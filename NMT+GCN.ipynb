{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NMT+GCN.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOT4P9+ueKS2xeWkW4GOKsl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"koblG7GNi6j_","colab_type":"text"},"source":["# Mount drive "]},{"cell_type":"code","metadata":{"id":"C--Krke-is1a","colab_type":"code","outputId":"eae2cce1-67d3-4ad4-e783-7cfd4e2fc9d7","executionInfo":{"status":"ok","timestamp":1587092299143,"user_tz":-540,"elapsed":968,"user":{"displayName":"Seokyoung Yoon","photoUrl":"","userId":"04017173576018407311"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0iuw9s6GtZe7","colab_type":"code","colab":{}},"source":["import sys\n","sys.path.append('/content/drive/My Drive/MLDL/NLP/pygcn-master/pygcn')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7J73DjqOi__J","colab_type":"text"},"source":["# Preprocessing\n","\n","Tokenization and paring"]},{"cell_type":"code","metadata":{"id":"k7Cs2oPZi_Bx","colab_type":"code","colab":{}},"source":["from __future__ import unicode_literals, print_function, division\n","from io import open\n","import unicodedata\n","import string\n","import re\n","import random\n","import time\n","import math \n","\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","import torch.nn.functional as F\n","\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JCoj5mkCjViP","colab_type":"code","colab":{}},"source":["SOS_token = 0\n","EOS_token = 1\n","\n","\n","class Lang:\n","    def __init__(self, name):\n","        self.name = name\n","        self.word2index = {}\n","        self.word2count = {}\n","        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n","        self.n_words = 2  # SOS 와 EOS 포함\n","\n","    def addSentence(self, sentence):\n","        for word in sentence.split(' '):\n","            self.addWord(word)\n","\n","    def addWord(self, word):\n","        if word not in self.word2index:\n","            self.word2index[word] = self.n_words\n","            self.word2count[word] = 1\n","            self.index2word[self.n_words] = word\n","            self.n_words += 1\n","        else:\n","            self.word2count[word] += 1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Mw8-UzGdzIpK","colab":{}},"source":["# Convert unicode strings to ASCII\n","def unicodeToAscii(s):\n","    return ''.join(\n","        c for c in unicodedata.normalize('NFD', s)\n","        if unicodedata.category(c) != 'Mn'\n","    )\n","\n","# 소문자, 다듬기, 그리고 문자가 아닌 문자 제거\n","\n","\n","def normalizeString(s):\n","    s = unicodeToAscii(s.lower().strip())\n","    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n","    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n","    return s"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"SKG6ZDTu6XLX","colab":{}},"source":["def readLangs(lang1, lang2, reverse=False):\n","  print(\"Reading lines...\")\n","\n","  # spliting text data by line\n","  lines = open('/content/drive/My Drive/Colab Notebooks/data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n","      read().strip().split('\\n')\n","\n","  # spliting lines by tap (splited into pairs)\n","  pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n","\n","  # reverse the pairs and create each Lang instance of two languages\n","  if reverse:\n","      pairs = [list(reversed(p)) for p in pairs]\n","      input_lang = Lang(lang2)\n","      output_lang = Lang(lang1)\n","  else:\n","      input_lang = Lang(lang1)\n","      output_lang = Lang(lang2)\n","\n","  return input_lang, output_lang, pairs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"dUBzXIN06me6","colab":{}},"source":["MAX_LENGTH = 10\n","\n","eng_prefixes = (\n","    \"i am \", \"i m \",\n","    \"he is\", \"he s \",\n","    \"she is\", \"she s \",\n","    \"you are\", \"you re \",\n","    \"we are\", \"we re \",\n","    \"they are\", \"they re \"\n",")\n","\n","\n","def filterPair(p):\n","    return len(p[0].split(' ')) < MAX_LENGTH and \\\n","        len(p[1].split(' ')) < MAX_LENGTH and \\\n","        p[1].startswith(eng_prefixes)\n","\n","\n","def filterPairs(pairs):\n","    return [pair for pair in pairs if filterPair(pair)]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JX4-5dHBPMrR","colab_type":"code","colab":{}},"source":["def indexesFromSentence(lang, sentence):\n","    return [lang.word2index[word] for word in sentence.split(' ')]\n","\n","\n","def tensorFromSentence(lang, sentence):\n","    indexes = indexesFromSentence(lang, sentence)\n","    indexes.append(EOS_token)\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n","\n","\n","def tensorsFromPair(pair):\n","    input_tensor = tensorFromSentence(input_lang, pair[0])\n","    target_tensor = tensorFromSentence(output_lang, pair[1])\n","    return (input_tensor, target_tensor)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1587092309315,"user_tz":-540,"elapsed":5178,"user":{"displayName":"Seokyoung Yoon","photoUrl":"","userId":"04017173576018407311"}},"id":"HneoFROhIGmv","outputId":"cc5d9228-065b-435a-9eb5-407b3a9f8370","colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["def prepareData(lang1, lang2, reverse=False):\n","    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n","    print(\"Read %s sentence pairs\" % len(pairs))\n","    pairs = filterPairs(pairs)\n","    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n","    print(\"Counting words...\")\n","    for pair in pairs:\n","        input_lang.addSentence(pair[0])\n","        output_lang.addSentence(pair[1])\n","    print(\"Counted words:\")\n","    print(input_lang.name, input_lang.n_words)\n","    print(output_lang.name, output_lang.n_words)\n","    return input_lang, output_lang, pairs\n","\n","\n","input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n","print(random.choice(pairs))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Reading lines...\n","Read 135842 sentence pairs\n","Trimmed to 10599 sentence pairs\n","Counting words...\n","Counted words:\n","fra 4345\n","eng 2803\n","['elle est mariee a un etranger .', 'she s married to a foreigner .']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"62meW_VOkDFd","colab_type":"text"},"source":["# Adjacency Matrix\n","\n","we use spacy model to construct dependecny tree"]},{"cell_type":"code","metadata":{"id":"bt6gRFOgykpS","colab_type":"code","outputId":"7c360756-4459-4cdf-f512-0a794fd84db8","executionInfo":{"status":"ok","timestamp":1587092313546,"user_tz":-540,"elapsed":8085,"user":{"displayName":"Seokyoung Yoon","photoUrl":"","userId":"04017173576018407311"}},"colab":{"base_uri":"https://localhost:8080/","height":496}},"source":["# Download spacy model (Gemran)\n","!python -m spacy download de"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: de_core_news_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz#egg=de_core_news_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n","Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (46.1.3)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.3)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.18.2)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.21.0)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.6.0)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.2)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.38.0)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.4.5.1)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.8)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.6.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.1.0)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('de_core_news_sm')\n","\u001b[38;5;2m✔ Linking successful\u001b[0m\n","/usr/local/lib/python3.6/dist-packages/de_core_news_sm -->\n","/usr/local/lib/python3.6/dist-packages/spacy/data/de\n","You can now load the model via spacy.load('de')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"llvLNWQLjiel","colab_type":"code","colab":{}},"source":["# Load Dependency Parsing function (German & English)\n","import spacy\n","from spacy import displacy\n","nlp = spacy.load('de')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"80kabPm_kXnS","colab_type":"code","outputId":"f5e8b085-032a-40b7-9182-8d38f74126ae","executionInfo":{"status":"ok","timestamp":1587092383333,"user_tz":-540,"elapsed":76509,"user":{"displayName":"Seokyoung Yoon","photoUrl":"","userId":"04017173576018407311"}},"colab":{"base_uri":"https://localhost:8080/","height":221}},"source":["# Make doc list of german sentences\n","input_sentence = [pair[0] for pair in pairs]\n","doc = []\n","print(\"reading german sentences...\")\n","for i in range(len(input_sentence)):\n","  doc.append(nlp(input_sentence[i]))\n","  if (i+1)%1000==0:\n","    print(str(i+1)+\" sentences were processed\")\n","\n","# Check length of list\n","print(str(len(doc))+\" sentences were preocessed\")"],"execution_count":12,"outputs":[{"output_type":"stream","text":["reading german sentences...\n","1000 sentences were processed\n","2000 sentences were processed\n","3000 sentences were processed\n","4000 sentences were processed\n","5000 sentences were processed\n","6000 sentences were processed\n","7000 sentences were processed\n","8000 sentences were processed\n","9000 sentences were processed\n","10000 sentences were processed\n","10599 sentences were preocessed\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"q8ogzvP_l_Fw","colab_type":"code","outputId":"70efc4e8-7145-43f6-f6ce-2d49f255545b","executionInfo":{"status":"ok","timestamp":1587092383333,"user_tz":-540,"elapsed":75860,"user":{"displayName":"Seokyoung Yoon","photoUrl":"","userId":"04017173576018407311"}},"colab":{"base_uri":"https://localhost:8080/","height":265}},"source":["# display dependency tree for a german sentence\n","print('depdendency tree for a german sentence')\n","displacy.render(doc[10], style='dep', jupyter=True, options={'distance': 90})"],"execution_count":13,"outputs":[{"output_type":"stream","text":["depdendency tree for a german sentence\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"de\" id=\"42474650588c43d0b1a350201282ab1d-0\" class=\"displacy\" width=\"320\" height=\"227.0\" direction=\"ltr\" style=\"max-width: none; height: 227.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"137.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">je</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADV</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"137.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"140\">suis</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"140\">PROPN</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"137.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"230\">timide .</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"230\">PROPN</tspan>\n","</text>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-42474650588c43d0b1a350201282ab1d-0-0\" stroke-width=\"2px\" d=\"M70,92.0 C70,2.0 230.0,2.0 230.0,92.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-42474650588c43d0b1a350201282ab1d-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mo</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M70,94.0 L62,82.0 78,82.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-42474650588c43d0b1a350201282ab1d-0-1\" stroke-width=\"2px\" d=\"M160,92.0 C160,47.0 225.0,47.0 225.0,92.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-42474650588c43d0b1a350201282ab1d-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pnc</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M160,94.0 L152,82.0 168,82.0\" fill=\"currentColor\"/>\n","</g>\n","</svg></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"LX0ffG1tkcbO","colab_type":"code","colab":{}},"source":["# Construct adjacency matrix\n","adjs=[]\n","for sen in range(len(doc)):\n","  # adj1, adj2, ..., adj10599 for each 1~10599 sentences\n","  globals()['adj{}'.format(sen)] = torch.zeros(len(doc[sen]),len(doc[sen]), device=device)\n","  for i in range(len(doc[sen])):\n","    # Dependency tree for each words\n","    globals()['doc{}_dep'.format(i)] = torch.zeros(len(doc[sen]), device=device)\n","    for j in range(len(doc[sen])):\n","      doc_head = doc[sen][i].head\n","      doc_child = set(list(doc[sen][i].children))\n","      globals()['doc{}_dep'.format(i)][j] = 1 if doc[sen][j]==doc[sen][i] or doc[sen][j]==doc_head or doc[sen][j] in doc_child else 0\n","    globals()['adj{}'.format(sen)][i] = globals()['doc{}_dep'.format(i)]\n","  adjs.append(globals()['adj{}'.format(sen)])    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wke-HOeekznm","colab_type":"code","outputId":"0de9877f-2e35-4d0d-f2d6-3f8eee6944fb","executionInfo":{"status":"ok","timestamp":1587092401801,"user_tz":-540,"elapsed":92692,"user":{"displayName":"Seokyoung Yoon","photoUrl":"","userId":"04017173576018407311"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Check shape of adjacency matrix sample\n","adjs[1000].shape"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([6, 6])"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"UG4x7L4IYASB","colab_type":"text"},"source":["# EncoderGCN Model"]},{"cell_type":"code","metadata":{"id":"tf7KvgUaV_sd","colab_type":"code","colab":{}},"source":["class EncoderGCN(nn.Module):\n","  def __init__(self, encoder, gcn):\n","    super().__init__()\n","    self.encoder = encoder\n","    self.gcn = gcn\n","  def forward(self, src, adj):\n","    # RNN (GRU)\n","    hidden = self.encoder.initHidden()\n","    features, hidden = self.encoder(src, hidden) # features = [input_length, batch_size, out_features]\n","    # GCN\n","    features = features.permute(1,0,2) # features = [batch_size, input_length, out_features]\n","    outputs = self.gcn(features, adj)\n","    dec_hid = torch.sum(outputs, dim=1)\n","    return outputs, dec_hid"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o6kAMe3GmnPt","colab_type":"text"},"source":["# Attention"]},{"cell_type":"code","metadata":{"id":"fb0ztU_BNfwS","colab_type":"code","colab":{}},"source":["class Attention(nn.Module):\n","    def __init__(self, enc_hid_dim, dec_hid_dim):\n","        super().__init__()\n","        \n","        self.attn = nn.Linear(enc_hid_dim + dec_hid_dim, dec_hid_dim)\n","        self.v = nn.Linear(dec_hid_dim, 1, bias = False)\n","        \n","    def forward(self, hidden, encoder_outputs):\n","        \n","        # hidden = [batch size, dec hid dim]\n","        # encoder_outputs = [batch size, src len, enc hid dim]\n","        \n","        batch_size = encoder_outputs.shape[0]\n","        src_len = encoder_outputs.shape[1]\n","        \n","        # repeat decoder hidden state src_len times\n","        hidden = hidden.repeat(1, src_len, 1)\n","                \n","        # hidden = [batch size, src len, dec hid dim]\n","        \n","        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2))) \n","        \n","        # energy = [batch size, src len, dec hid dim]\n","\n","        attention = self.v(energy).squeeze(2)\n","        \n","        # attention= [batch size, src len]\n","        \n","        return F.softmax(attention, dim=1)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o7uiuwz4nxlk","colab_type":"text"},"source":["# Decoder"]},{"cell_type":"code","metadata":{"id":"GEf1hcsrN0GQ","colab_type":"code","colab":{}},"source":["class Decoder(nn.Module):\n","    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n","        super().__init__()\n","\n","        self.output_dim = output_dim\n","        self.attention = attention\n","        \n","        self.embedding = nn.Embedding(output_dim, emb_dim)\n","        \n","        self.rnn = nn.GRU(enc_hid_dim + emb_dim, dec_hid_dim)\n","        \n","        self.fc_out = nn.Linear(enc_hid_dim + dec_hid_dim + emb_dim, output_dim)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, input, hidden, encoder_outputs):\n","             \n","        # input = [batch size]\n","        # hidden = [batch size, dec hid dim]\n","        # encoder_outputs = [batch size, src len, enc hid dim]\n","        \n","        input = input.unsqueeze(0)\n","        \n","        # input = [1, batch size]\n","        \n","        embedded = self.dropout(self.embedding(input))\n","        \n","        # embedded = [1, batch size, emb dim]\n","        \n","        a = self.attention(hidden, encoder_outputs)\n","                \n","        # a = [batch size, src len]\n","        \n","        a = a.unsqueeze(1)\n","        \n","        # a = [batch size, 1, src len]\n","        \n","        weighted = torch.bmm(a, encoder_outputs)\n","        \n","        # weighted = [batch size, 1, enc hid dim ]\n","        \n","        weighted = weighted.permute(1, 0, 2)\n","        \n","        # weighted = [1, batch size, enc hid dim ]\n","        \n","        rnn_input = torch.cat((embedded, weighted), dim = 2)\n","        \n","        # rnn_input = [1, batch size, enc hid dim + emb dim]\n","            \n","        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n","        # output = [seq len, batch size, dec hid dim * n directions]\n","        # hidden = [n layers * n directions, batch size, dec hid dim]\n","        \n","        # seq len, n layers and n directions will always be 1 in this decoder, therefore:\n","        # output = [1, batch size, dec hid dim]\n","        # hidden = [1, batch size, dec hid dim]\n","        # this also means that output == hidden\n","        assert (output == hidden).all()\n","        \n","        embedded = embedded.squeeze(0)\n","        output = output.squeeze(0)\n","        weighted = weighted.squeeze(0)\n","        \n","        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim = 1))\n","        \n","        # prediction = [batch size, output dim]\n","        \n","        return prediction, hidden.squeeze(0)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6uAoB5VxtcH1","colab_type":"text"},"source":["# Seq2seq Model"]},{"cell_type":"code","metadata":{"id":"hE5Xei5nZvYy","colab_type":"code","colab":{}},"source":["class seq2seq(nn.Module):\n","  def __init__(self, encoder, decoder):\n","    super().__init__()\n","    self.encoder = encoder\n","    self.decoder = decoder\n","\n","  def forward(self, src, adj, trg, teacher_forcing_ratio = 0.5):\n","    batch_size = src.shape[1]\n","    trg_len = trg.shape[0]\n","    trg_vocab_size = self.decoder.output_dim\n","    \n","    # tensor to store decoder outputs\n","    outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(device)\n","\n","    # output and hidden state of EncoderGCN\n","    encoder_outputs, hidden = self.encoder(src, adj)\n","\n","    # first input to the decoder is the <sos> tokens\n","    input = trg[0,:]\n","\n","    for t in range(1, trg_len):\n","      output, hidden = self.decoder(input, hidden, encoder_outputs)\n","      outputs[t] = output\n","    \n","    # decide if we are going to use teacher forcing or not\n","      teacher_force = random.random() < teacher_forcing_ratio\n","\n","    # get the highest predicted token from our predictions\n","      top1 = output.argmax(1) \n","\n","    # if teacher forcing, use actual next token as next input\n","    # if not, use predicted token\n","      input = trg[t] if teacher_force else top1\n","\n","    return outputs"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c6SOpNRvAX9t","colab_type":"text"},"source":["# Training the Seq2Seq model\n","\n","We initialize our EncoderRNN, GCN, Decoder and seq2Seq model"]},{"cell_type":"code","metadata":{"id":"NiKReZiE0MSJ","colab_type":"code","colab":{}},"source":["from models import GCN, EncoderRNN\n","\n","# Tokenization\n","germ_tensors = [tensorFromSentence(input_lang, pair[0]) for pair in pairs]\n","germ_tensor = germ_tensors[1000][:-1]\n","\n","eng_tensors = [tensorFromSentence(output_lang, pair[1]) for pair in pairs]\n","eng_tensor = eng_tensors[1000][:-1]\n","\n","\n","# EncdoerRNN and GCN\n","enc_hid_dim = 256\n","gcn_hid_dim_1 = 256\n","gcn_hid_dim_2 = 512\n","\n","encoder = EncoderRNN(input_lang.n_words, enc_hid_dim)\n","gcn = GCN(nfeat=enc_hid_dim,\n","            nhid=gcn_hid_dim_1,\n","            nclass=gcn_hid_dim_2,\n","            dropout=0.5)\n","\n","# EncoderGCN\n","enc_gcn = EncoderGCN(encoder, gcn)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nL5FwmTDb822","colab_type":"code","colab":{}},"source":["# Attention and Decoder \n","embed_dim = 256\n","dec_hid_dim = 512\n","dec_dropout = 0.5\n","\n","attn = Attention(gcn_hid_dim_2, dec_hid_dim)\n","dec = Decoder(output_lang.n_words, embed_dim , gcn_hid_dim_2, dec_hid_dim, dec_dropout, attn)\n","\n","# seq2seq \n","model = seq2seq(enc_gcn, dec).to(device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i48UzBvmLbwO","colab_type":"code","colab":{}},"source":["output=model(germ_tensor, adj1000.unsqueeze(0), eng_tensor)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wIM0FZZOBdfP","colab_type":"text"},"source":["## We initialize weights by N(0,0) and bias to 0"]},{"cell_type":"code","metadata":{"id":"Wx_LuvWpBc_j","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":391},"outputId":"81940b43-72ba-418e-9976-d0c3228b8a1b","executionInfo":{"status":"ok","timestamp":1587095618132,"user_tz":-540,"elapsed":508,"user":{"displayName":"Seokyoung Yoon","photoUrl":"","userId":"04017173576018407311"}}},"source":["def init_weights(m):\n","    for name, param in m.named_parameters():\n","        if 'weight' in name:\n","            nn.init.normal_(param.data, mean=0, std=0.01)\n","        else:\n","            nn.init.constant_(param.data, 0)\n","            \n","model.apply(init_weights)"],"execution_count":98,"outputs":[{"output_type":"execute_result","data":{"text/plain":["seq2seq(\n","  (encoder): EncoderGCN(\n","    (encoder): EncoderRNN(\n","      (embedding): Embedding(4345, 256)\n","      (gru): GRU(256, 256)\n","    )\n","    (gcn): GCN(\n","      (gc1): GraphConvolution (256 -> 256)\n","      (gc2): GraphConvolution (256 -> 512)\n","    )\n","  )\n","  (decoder): Decoder(\n","    (attention): Attention(\n","      (attn): Linear(in_features=1024, out_features=512, bias=True)\n","      (v): Linear(in_features=512, out_features=1, bias=False)\n","    )\n","    (embedding): Embedding(2803, 256)\n","    (rnn): GRU(768, 512)\n","    (fc_out): Linear(in_features=1280, out_features=2803, bias=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":98}]},{"cell_type":"markdown","metadata":{"id":"KD6-8IUKFTt5","colab_type":"text"},"source":["## We set optimizer and loss function"]},{"cell_type":"code","metadata":{"id":"UlH281QvE5KP","colab_type":"code","colab":{}},"source":["# Optimizer setting\n","optimizer = optim.Adam(model.parameters())\n","\n","# Initializing loss function\n","criterion = nn.CrossEntropyLoss()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"J3wmoEMbIbUi","colab_type":"code","colab":{}},"source":["def train(model, iterators, optimizer, criterion, clip):\n","    \n","    model.train()\n","    \n","    epoch_loss = 0\n","    \n","    for i, (src, adjs, trg) in enumerate(iterators):\n","      \n","        optimizer.zero_grad()\n","        \n","        # To delete '.' in the end of squences\n","        output = model(src[:-1], adjs.unsqueeze(0), trg)\n","                \n","        output_dim = output.shape[-1]\n","        \n","        output = output[1:].view(-1, output_dim)\n","        trg = trg[1:].view(-1)\n","        \n","        #trg = [(trg len - 1) * batch size]\n","        #output = [(trg len - 1) * batch size, output dim]\n","        \n","        loss = criterion(output, trg)\n","        \n","        loss.backward()\n","        \n","        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","        \n","        optimizer.step()\n","        \n","        epoch_loss += loss.item()\n","        \n","        length = i+1 \n","        \n","    return epoch_loss / length"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yTz_LdO59twA","colab_type":"code","colab":{}},"source":["def evaluate(model, iterators, criterion):\n","    \n","    model.eval()\n","    \n","    epoch_loss = 0\n","    \n","    with torch.no_grad():\n","    \n","        for i, (src, adjs, trg) in enumerate(iterators):\n","\n","            output = model(src[:-1], adjs.unsqueeze(0), trg, teacher_forcing_ratio = 0) #turn off teacher forcing\n","\n","            #trg = [trg len, batch size]\n","            #output = [trg len, batch size, output dim]\n","\n","            output_dim = output.shape[-1]\n","            \n","            output = output[1:].view(-1, output_dim)\n","            trg = trg[1:].view(-1)\n","\n","            #trg = [(trg len - 1) * batch size]\n","            #output = [(trg len - 1) * batch size, output dim]\n","\n","            loss = criterion(output, trg)\n","\n","            epoch_loss += loss.item()\n","\n","            length = i+1\n","        \n","    return epoch_loss / length"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ox21gX8f9vYG","colab_type":"code","colab":{}},"source":["def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3I-80dd2JJdf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"67c2bceb-7145-4d09-b1f2-302d2a4b5d65","executionInfo":{"status":"ok","timestamp":1587095622709,"user_tz":-540,"elapsed":676,"user":{"displayName":"Seokyoung Yoon","photoUrl":"","userId":"04017173576018407311"}}},"source":["print(germ_tensors[0].shape, adjs[0].shape)"],"execution_count":103,"outputs":[{"output_type":"stream","text":["torch.Size([5, 1]) torch.Size([4, 4])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AUcmoDVKMxvB","colab_type":"code","colab":{}},"source":["N_EPOCHS = 10\n","CLIP = 1\n","\n","train_iterator = zip(germ_tensors, adjs, eng_tensors)\n","\n","best_valid_loss = float('inf')\n","\n","for epoch in range(N_EPOCHS):\n","    \n","    start_time = time.time()\n","    \n","    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n","    \n","    end_time = time.time()\n","    \n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","        \n","    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n","\n","torch.save(model.state_dict(), 'tut3-model.pt')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5c7UtuxuM56b","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}